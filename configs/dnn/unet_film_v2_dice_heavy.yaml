# ===================================================================
# Training Configuration for U-Net+FiLM Oracle - V2 Dice-Heavy
# ===================================================================

# -- Experiment identifiers and reproducibility --
run_name: unet_film_v2_dice_heavy  # Updated: Name for this specific run
seed: 42                           # Kept constant for fair comparison

# -- Dataset locations and split ratios --
samples_dir: training_data
ground_truth_dir: ground_truth
val_split: 0.1

# -- Output directories for checkpoints and TensorBoard logs --
checkpoints_dir: checkpoints/unet_film_v2_dice_heavy # Updated: Separate output folder
log_dir: logs/unet_film_v2_dice_heavy            # Updated: Separate log folder

# -- Training parameters --
device: cuda
epochs: 50
batch_size: 8
num_workers: 12
use_amp: true
early_stop_patience: 10

# -- Optimizer configuration --
optimizer:
  name: AdamW
  lr: 0.001
  weight_decay: 0.0001

# -- Learning rate scheduler settings --
scheduler:
  name: CosineAnnealing
  warmup_epochs: 5

# -- Loss function weighting --
# CHANGED: Prioritizing Dice loss to enforce spatial precision.
loss:
  dice_weight: 0.8    # Increased from 0.5
  focal_weight: 0.2   # Decreased from 0.5
  focal_gamma: 2.0
